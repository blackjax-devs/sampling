{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43aed921",
   "metadata": {},
   "source": [
    "# Bayesian Logistic Regression With Latent Gaussian Sampler\n",
    "\n",
    "In this notebook we reproduce the Logistic Regression example, but by directly leveraging the fact that the prior is Gaussian to use the latent Gaussian model. Most of the code is the same as in the previous notebook, but the sampler (and the adaptation step) will differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_biclusters\n",
    "\n",
    "import blackjax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622ab8c",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8fff3",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We create two clusters of points using [scikit-learn's `make_bicluster` function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_biclusters.html?highlight=bicluster%20data#sklearn.datasets.make_biclusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa428aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "X, rows, cols = make_biclusters(\n",
    "    (num_points, 2), 2, noise=0.6, random_state=314, minval=-3, maxval=3\n",
    ")\n",
    "y = rows[0] * 1.0  # y[i] = whether point i belongs to cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a126ca",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "colors = [\"tab:red\" if el else \"tab:blue\" for el in rows[0]]\n",
    "plt.scatter(*X.T, edgecolors=colors, c=\"none\")\n",
    "plt.xlabel(r\"$X_0$\")\n",
    "plt.ylabel(r\"$X_1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d936d29",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "We use a simple logistic regression model to infer to which cluster each of the points belongs. We note $y$ a binary variable that indicates whether a point belongs to the first cluster :\n",
    "\n",
    "$$\n",
    "y \\sim \\operatorname{Bernoulli}(p)\n",
    "$$\n",
    "\n",
    "The probability $p$ to belong to the first cluster commes from a logistic regression:\n",
    "\n",
    "$$\n",
    "p = \\operatorname{logistic}(\\Phi\\,\\boldsymbol{w})\n",
    "$$\n",
    "\n",
    "where $w$ is a vector of weights whose priors are a normal prior centered on 0:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{w} \\sim \\operatorname{Normal}(0, \\sigma)\n",
    "$$\n",
    "\n",
    "And $\\Phi$ is the matrix that contains the data, so each row $\\Phi_{i,:}$ is the vector $\\left[1, X_0^i, X_1^i\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94c866",
   "metadata": {
    "tags": [
     "hide-stderr"
    ]
   },
   "outputs": [],
   "source": [
    "Phi = jnp.c_[jnp.ones(num_points)[:, None], X]\n",
    "N, M = Phi.shape\n",
    "alpha = 1.0\n",
    "C = jnp.eye(M) / alpha  # covariance of the prior for the weights\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return jnp.exp(z) / (1 + jnp.exp(z))\n",
    "\n",
    "\n",
    "def log_sigmoid(z):\n",
    "    return z - jnp.log(1 + jnp.exp(z))\n",
    "\n",
    "\n",
    "def log_likelihood(w):\n",
    "    \"\"\"The log-probability density function of the posterior distribution of the model.\"\"\"\n",
    "    log_an = log_sigmoid(Phi @ w)\n",
    "    an = Phi @ w\n",
    "    log_likelihood_term = y * log_an + (1 - y) * jnp.log(1 - sigmoid(an))\n",
    "\n",
    "    return log_likelihood_term.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977a086",
   "metadata": {},
   "source": [
    "## Posterior sampling\n",
    "\n",
    "We use `blackjax`'s Latent Gaussian sampler to sample from the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1582d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(314)\n",
    "\n",
    "w0 = jnp.zeros((M,))\n",
    "\n",
    "init, step = blackjax.mgrad_gaussian(log_likelihood, C)\n",
    "initial_state = init(w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c249a8",
   "metadata": {},
   "source": [
    "We first define a calibration loop. The goal is to find the \"step-size\" `delta` that approximately corresponds to an acceptance probability of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6511feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_loop(\n",
    "    rng_key,\n",
    "    initial_state,\n",
    "    initial_delta,\n",
    "    num_steps,\n",
    "    update_every=100,\n",
    "    target=0.5,\n",
    "    rate=0.5,\n",
    "):\n",
    "    def body(carry):\n",
    "        i, state, delta, pct_accepted, rng_key = carry\n",
    "        rng_key, rng_key2 = jax.random.split(rng_key, 2)\n",
    "        state, info = step(rng_key, state, delta)\n",
    "\n",
    "        # restart calibration of delta\n",
    "        j = i % update_every\n",
    "        pct_accepted = (j * pct_accepted + info.is_accepted) / (j + 1)\n",
    "        diff = target - pct_accepted\n",
    "        delta = jax.lax.cond(\n",
    "            j == 0, lambda _: delta * (1 - diff * rate), lambda _: delta, None\n",
    "        )\n",
    "\n",
    "        return i + 1, state, delta, pct_accepted, rng_key2\n",
    "\n",
    "    _, final_state, final_delta, final_pct_accepted, _ = jax.lax.while_loop(\n",
    "        lambda carry: carry[0] < num_steps,\n",
    "        body,\n",
    "        (0, initial_state, initial_delta, 0.0, rng_key),\n",
    "    )\n",
    "\n",
    "    return final_state, final_delta\n",
    "\n",
    "\n",
    "def inference_loop(rng_key, initial_delta, initial_state, num_samples, num_burnin):\n",
    "    rng_key, rng_key2 = jax.random.split(rng_key, 2)\n",
    "\n",
    "    initial_state, delta = calibration_loop(\n",
    "        rng_key, initial_state, initial_delta, num_burnin\n",
    "    )\n",
    "\n",
    "    @jax.jit\n",
    "    def one_step(carry, rng_key):\n",
    "        i, pct_accepted, state = carry\n",
    "        state, info = step(rng_key, state, delta)\n",
    "        pct_accepted = (i * pct_accepted + info.is_accepted) / (i + 1)\n",
    "        return (i + 1, pct_accepted, state), state\n",
    "\n",
    "    keys = jax.random.split(rng_key, num_samples)\n",
    "    (_, tota_pct_accepted, _), states = jax.lax.scan(\n",
    "        one_step, (0, 0.0, initial_state), keys\n",
    "    )\n",
    "    return states, tota_pct_accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536802f",
   "metadata": {},
   "source": [
    "We can now run the inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2295635",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, rng_key = random.split(rng_key)\n",
    "states, tota_pct_accepted = inference_loop(rng_key, 0.5, initial_state, 5_000, 1_000)\n",
    "print(f\"Percentage of accepted samples (after calibration): {tota_pct_accepted:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a89b8fd",
   "metadata": {},
   "source": [
    "And display the trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a11a74",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 2))\n",
    "for i, axi in enumerate(ax):\n",
    "    axi.plot(states.position[:, i])\n",
    "    axi.set_title(f\"$w_{i}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = states.position\n",
    "nsamp, _ = chains.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c7a05",
   "metadata": {},
   "source": [
    "### Predictive distribution\n",
    "\n",
    "Having infered the posterior distribution of the regression's coefficients we can compute the probability to belong to the first cluster at each position $(X_0, X_1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a meshgrid\n",
    "xmin, ymin = X.min(axis=0) - 0.1\n",
    "xmax, ymax = X.max(axis=0) + 0.1\n",
    "step = 0.1\n",
    "Xspace = jnp.mgrid[xmin:xmax:step, ymin:ymax:step]\n",
    "_, nx, ny = Xspace.shape\n",
    "\n",
    "# Compute the average probability to belong to the first cluster at each point on the meshgrid\n",
    "Phispace = jnp.concatenate([jnp.ones((1, nx, ny)), Xspace])\n",
    "Z_mcmc = sigmoid(jnp.einsum(\"mij,sm->sij\", Phispace, chains))\n",
    "Z_mcmc = Z_mcmc.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d121fd",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.contourf(*Xspace, Z_mcmc)\n",
    "plt.scatter(*X.T, c=colors)\n",
    "plt.xlabel(r\"$X_0$\")\n",
    "plt.ylabel(r\"$X_1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f68d86",
   "metadata": {},
   "source": [
    "We essentially recover the same contours as with the standard random walk approach."
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "mystnb": {
   "execution_timeout": 200
  },
  "source_map": [
   15,
   21,
   31,
   37,
   43,
   51,
   59,
   83,
   107,
   113,
   120,
   124,
   177,
   181,
   185,
   189,
   199,
   202,
   208,
   222,
   230
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}