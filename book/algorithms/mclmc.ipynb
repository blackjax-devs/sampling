{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ca41b3",
   "metadata": {},
   "source": [
    "# Microcanonical Langevin Monte Carlo\n",
    "\n",
    "This is an algorithm based on https://arxiv.org/abs/2212.08549 ({cite:p}`robnik2023microcanonical`, {cite:p}`robnik2023microcanonical2`). A website with detailed information can be found [here](https://microcanonical-monte-carlo.netlify.app/). The algorithm is provided in both adjusted (i.e. with an Metropolis-Hastings step) and unadjusted versions; by default we use \"MCLMC\" to refer to the unadjusted version.\n",
    "\n",
    "The original derivation comes from thinking about the microcanonical ensemble (a concept from statistical mechanics), but the upshot is that we integrate the following SDE:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt}\\begin{bmatrix}\n",
    "x \\\\\n",
    "u\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "u \\\\\n",
    "-P(u)(\\nabla S(x)/(d âˆ’ 1)) + \\eta P(u)dW\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $u$ is an auxilliary variable, $S(x)$ is the negative log PDF of the distribution from which we are sampling and the last term describes spherically symmetric noise. After $u$ is marginalized out, this converges to the target PDF, $p(x) \\propto e^{-S(x)}$.\n",
    "\n",
    "## How to run MCLMC in BlackJax\n",
    "\n",
    "It is very important to use the tuning algorithm provided, which controls the step size of the integrator and also $L$, a parameter related to $\\eta$ above.\n",
    "\n",
    "An example is given below, of a 1000 dim Gaussian (of which 2 dimensions are plotted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f2a9b",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"font.size\"] = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf07bc",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "rng_key = jax.random.key(int(date.today().strftime(\"%Y%m%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e40114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import blackjax\n",
    "from blackjax.mcmc.adjusted_mclmc import rescale\n",
    "import numpy as np\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3066e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mclmc(logdensity_fn, num_steps, initial_position, key, transform):\n",
    "    init_key, tune_key, run_key = jax.random.split(key, 3)\n",
    "\n",
    "    # create an initial state for the sampler\n",
    "    initial_state = blackjax.mcmc.mclmc.init(\n",
    "        position=initial_position, logdensity_fn=logdensity_fn, rng_key=init_key\n",
    "    )\n",
    "\n",
    "    # build the kernel\n",
    "    kernel = lambda sqrt_diag_cov : blackjax.mcmc.mclmc.build_kernel(\n",
    "        logdensity_fn=logdensity_fn,\n",
    "        integrator=blackjax.mcmc.integrators.isokinetic_mclachlan,\n",
    "        sqrt_diag_cov=sqrt_diag_cov,\n",
    "    )\n",
    "\n",
    "    # find values for L and step_size\n",
    "    (\n",
    "        blackjax_state_after_tuning,\n",
    "        blackjax_mclmc_sampler_params,\n",
    "    ) = blackjax.mclmc_find_L_and_step_size(\n",
    "        mclmc_kernel=kernel,\n",
    "        num_steps=num_steps,\n",
    "        state=initial_state,\n",
    "        rng_key=tune_key,\n",
    "        diagonal_preconditioning=False,\n",
    "    )\n",
    "\n",
    "    # use the quick wrapper to build a new kernel with the tuned parameters\n",
    "    sampling_alg = blackjax.mclmc(\n",
    "        logdensity_fn,\n",
    "        L=blackjax_mclmc_sampler_params.L,\n",
    "        step_size=blackjax_mclmc_sampler_params.step_size,\n",
    "    )\n",
    "\n",
    "    # run the sampler\n",
    "    _, samples, _ = blackjax.util.run_inference_algorithm(\n",
    "        rng_key=run_key,\n",
    "        initial_state=blackjax_state_after_tuning,\n",
    "        inference_algorithm=sampling_alg,\n",
    "        num_steps=num_steps,\n",
    "        transform=transform,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66979e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the algorithm on a high dimensional gaussian, and show two of the dimensions\n",
    "\n",
    "sample_key, rng_key = jax.random.split(rng_key)\n",
    "samples = run_mclmc(\n",
    "    logdensity_fn=lambda x: -0.5 * jnp.sum(jnp.square(x)),\n",
    "    num_steps=1000,\n",
    "    initial_position=jnp.ones((1000,)),\n",
    "    key=sample_key,\n",
    "    transform=lambda x: x.position[:2],\n",
    ")\n",
    "samples.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a740793",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=samples[:, 0], y=samples[:, 1], alpha=0.1)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Scatter Plot of Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d298a46",
   "metadata": {},
   "source": [
    "# Second example: Stochastic Volatility\n",
    "\n",
    "This is ported from Jakob Robnik's [example notebook](https://github.com/JakobRobnik/MicroCanonicalHMC/blob/master/notebooks/tutorials/advanced_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea3b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "from numpyro.examples.datasets import SP500, load_dataset\n",
    "from numpyro.distributions import StudentT\n",
    "\n",
    "# get the data\n",
    "_, fetch = load_dataset(SP500, shuffle=False)\n",
    "SP500_dates, SP500_returns = fetch()\n",
    "\n",
    "\n",
    "# figure setup\n",
    "_, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.spines[\"right\"].set_visible(False)  # remove the upper and the right axis lines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())  # dates on the xaxis\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "\n",
    "# plot data\n",
    "dates = mdates.num2date(mdates.datestr2num(SP500_dates))\n",
    "ax.plot(dates, SP500_returns, \".\", markersize=3, color=\"steelblue\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"S&P500 returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2429\n",
    "\n",
    "lambda_sigma, lambda_nu = 50, 0.1\n",
    "\n",
    "\n",
    "def logp_volatility(x):\n",
    "    \"\"\"log p of the target distribution\"\"\"\n",
    "\n",
    "    sigma = (\n",
    "        jnp.exp(x[-2]) / lambda_sigma\n",
    "    )  # we used log-transformation to make x unconstrained\n",
    "    nu = jnp.exp(x[-1]) / lambda_nu\n",
    "\n",
    "    prior2 = (jnp.exp(x[-2]) - x[-2]) + (\n",
    "        jnp.exp(x[-1]) - x[-1]\n",
    "    )  # - log prior(sigma, nu)\n",
    "    prior1 = (dim - 2) * jnp.log(sigma) + 0.5 * (\n",
    "        jnp.square(x[0]) + jnp.sum(jnp.square(x[1:-2] - x[:-3]))\n",
    "    ) / jnp.square(\n",
    "        sigma\n",
    "    )  # - log prior(R)\n",
    "    lik = -jnp.sum(\n",
    "        StudentT(df=nu, scale=jnp.exp(x[:-2])).log_prob(SP500_returns)\n",
    "    )  # - log likelihood\n",
    "\n",
    "    return -(lik + prior1 + prior2)\n",
    "\n",
    "\n",
    "def transform(x):\n",
    "    \"\"\"transform x back to the parameters R, sigma and nu (taking the exponent)\"\"\"\n",
    "\n",
    "    Rn = jnp.exp(x[:-2])\n",
    "    sigma = jnp.exp(x[-2]) / lambda_sigma\n",
    "    nu = jnp.exp(x[-1]) / lambda_nu\n",
    "\n",
    "    return jnp.concatenate((Rn, jnp.array([sigma, nu])))\n",
    "\n",
    "\n",
    "def prior_draw(key):\n",
    "    \"\"\"draws x from the prior\"\"\"\n",
    "\n",
    "    key_walk, key_exp1, key_exp2 = jax.random.split(key, 3)\n",
    "\n",
    "    sigma = (\n",
    "        jax.random.exponential(key_exp1) / lambda_sigma\n",
    "    )  # sigma is drawn from the exponential distribution\n",
    "\n",
    "    def step(track, useless):  # one step of the gaussian random walk\n",
    "        randkey, subkey = jax.random.split(track[1])\n",
    "        x = (\n",
    "            jax.random.normal(subkey, shape=track[0].shape, dtype=track[0].dtype)\n",
    "            + track[0]\n",
    "        )\n",
    "        return (x, randkey), x\n",
    "\n",
    "    x = jnp.empty(dim)\n",
    "    x = x.at[:-2].set(\n",
    "        jax.lax.scan(step, init=(0.0, key_walk), xs=None, length=dim - 2)[1] * sigma\n",
    "    )  # = log R_n are drawn as a Gaussian random walk realization\n",
    "    x = x.at[-2].set(\n",
    "        jnp.log(sigma * lambda_sigma)\n",
    "    )  # sigma ~ exponential distribution(lambda_sigma)\n",
    "    x = x.at[-1].set(\n",
    "        jnp.log(jax.random.exponential(key_exp2))\n",
    "    )  # nu ~ exponential distribution(lambda_nu)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2, rng_key = jax.random.split(rng_key, 3)\n",
    "samples = run_mclmc(\n",
    "    logdensity_fn=logp_volatility,\n",
    "    num_steps=10000,\n",
    "    initial_position=prior_draw(key1),\n",
    "    key=key2,\n",
    "    transform=lambda x: x,\n",
    ")\n",
    "\n",
    "samples = transform(samples.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array(samples)[:, :-2]  # remove sigma and nu parameters\n",
    "R = np.sort(R, axis=0)  # sort samples for each R_n\n",
    "num_samples = len(R)\n",
    "lower_quartile, median, upper_quartile = (\n",
    "    R[num_samples // 4, :],\n",
    "    R[num_samples // 2, :],\n",
    "    R[3 * num_samples // 4, :],\n",
    ")\n",
    "\n",
    "# figure setup\n",
    "_, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.spines[\"right\"].set_visible(False)  # remove the upper and the right axis lines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())  # dates on the xaxis\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "\n",
    "# plot data\n",
    "ax.plot(dates, SP500_returns, \".\", markersize=3, color=\"steelblue\")\n",
    "ax.plot(\n",
    "    [], [], \".\", markersize=10, color=\"steelblue\", alpha=0.5, label=\"data\"\n",
    ")  # larger markersize for the legend\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"S&P500 returns\")\n",
    "\n",
    "# plot posterior\n",
    "ax.plot(dates, median, color=\"navy\", label=\"volatility posterior\")\n",
    "ax.fill_between(dates, lower_quartile, upper_quartile, color=\"navy\", alpha=0.5)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39f869",
   "metadata": {},
   "source": [
    "## Adjusted MCLMC\n",
    "\n",
    "Blackjax also provides an adjusted version of the algorithm. This also has two hyperparameters, `step_size` and `L`. `L` is related to the `L` parameter of the unadjusted version, but not identical. The tuning algorithm is also similar, but uses a dual averaging scheme to tune the step size. We find in practice that a target MH acceptance rate of 0.9 is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adjusted_mclmc(logdensity_fn, num_steps, initial_position, key, transform):\n",
    "    init_key, tune_key, run_key = jax.random.split(key, 3)\n",
    "\n",
    "    # create an initial state for the sampler\n",
    "    initial_state = blackjax.mcmc.adjusted_mclmc.init(\n",
    "        position=initial_position, logdensity_fn=logdensity_fn, random_generator_arg=init_key\n",
    "    )\n",
    "\n",
    "    kernel = lambda rng_key, state, avg_num_integration_steps, step_size, sqrt_diag_cov: blackjax.mcmc.adjusted_mclmc.build_kernel(\n",
    "                integrator=blackjax.mcmc.integrators.isokinetic_mclachlan,\n",
    "                integration_steps_fn = lambda k : jnp.ceil(jax.random.uniform(k) * rescale(avg_num_integration_steps)),\n",
    "                sqrt_diag_cov=sqrt_diag_cov,\n",
    "            )(\n",
    "                rng_key=rng_key, \n",
    "                state=state, \n",
    "                step_size=step_size, \n",
    "                logdensity_fn=logdensity_fn)\n",
    "    \n",
    "    \n",
    "    (\n",
    "        blackjax_state_after_tuning,\n",
    "        blackjax_mclmc_sampler_params,\n",
    "        params_history,\n",
    "        final_da\n",
    "    ) = blackjax.adaptation.mclmc_adaptation.adjusted_mclmc_find_L_and_step_size(\n",
    "        mclmc_kernel=kernel,\n",
    "        num_steps=num_steps,\n",
    "        state=initial_state,\n",
    "        rng_key=tune_key,\n",
    "        target=0.9,\n",
    "        frac_tune1=0.1,\n",
    "        frac_tune2=0.1,\n",
    "        frac_tune3=0.1,\n",
    "        diagonal_preconditioning=False,\n",
    "    )\n",
    "\n",
    "\n",
    "    step_size = blackjax_mclmc_sampler_params.step_size\n",
    "    L = blackjax_mclmc_sampler_params.L\n",
    "\n",
    "    alg = blackjax.adjusted_mclmc(\n",
    "        logdensity_fn=logdensity_fn,\n",
    "        step_size=step_size,\n",
    "        integration_steps_fn = lambda key: jnp.ceil(jax.random.uniform(key) * rescale(L/step_size)) ,\n",
    "        integrator=blackjax.mcmc.integrators.isokinetic_mclachlan,\n",
    "        sqrt_diag_cov=blackjax_mclmc_sampler_params.sqrt_diag_cov,\n",
    "        \n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    _, samples, info = blackjax.util.run_inference_algorithm(\n",
    "        rng_key=run_key,\n",
    "        initial_state=blackjax_state_after_tuning,\n",
    "        inference_algorithm=alg,\n",
    "        num_steps=num_steps, \n",
    "        transform=lambda x: x.position, \n",
    "        progress_bar=True)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the algorithm on a high dimensional gaussian, and show two of the dimensions\n",
    "\n",
    "sample_key, rng_key = jax.random.split(rng_key)\n",
    "samples = run_adjusted_mclmc(\n",
    "    logdensity_fn=lambda x: -0.5 * jnp.sum(jnp.square(x)),\n",
    "    num_steps=1000,\n",
    "    initial_position=jnp.ones((1000,)),\n",
    "    key=sample_key,\n",
    "    transform=lambda x: x.position[:2],\n",
    ")\n",
    "plt.scatter(x=samples[:, 0], y=samples[:, 1], alpha=0.1)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Scatter Plot of Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd99d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2, rng_key = jax.random.split(rng_key, 3)\n",
    "samples = run_adjusted_mclmc(\n",
    "    logdensity_fn=logp_volatility,\n",
    "    num_steps=10000,\n",
    "    initial_position=prior_draw(key1),\n",
    "    key=key2,\n",
    "    transform=lambda x: x,\n",
    ")\n",
    "\n",
    "R = np.array(samples)[:, :-2]  # remove sigma and nu parameters\n",
    "R = np.sort(R, axis=0)  # sort samples for each R_n\n",
    "num_samples = len(R)\n",
    "lower_quartile, median, upper_quartile = (\n",
    "    R[num_samples // 4, :],\n",
    "    R[num_samples // 2, :],\n",
    "    R[3 * num_samples // 4, :],\n",
    ")\n",
    "\n",
    "# figure setup\n",
    "_, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.spines[\"right\"].set_visible(False)  # remove the upper and the right axis lines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())  # dates on the xaxis\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "\n",
    "# plot data\n",
    "ax.plot(dates, SP500_returns, \".\", markersize=3, color=\"steelblue\")\n",
    "ax.plot(\n",
    "    [], [], \".\", markersize=10, color=\"steelblue\", alpha=0.5, label=\"data\"\n",
    ")  # larger markersize for the legend\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"S&P500 returns\")\n",
    "\n",
    "# plot posterior\n",
    "ax.plot(dates, median, color=\"navy\", label=\"volatility posterior\")\n",
    "ax.fill_between(dates, lower_quartile, upper_quartile, color=\"navy\", alpha=0.5)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b1d92",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mclmc",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
